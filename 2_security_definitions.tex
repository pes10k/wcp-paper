\section{Security Definitions}

This section defines several security related terms that are used through out this paper.  The terminology is not identical throughout the literature, but have mappings onto similar, equivalent terms.


\subsection{Properties of \ac{SFE} System}

Attempting to abstractly but precisely defining the characteristics of a \ac{SFE} protocol is difficult and can quickly devolve into a long enumeration of characteristics a \ac{SFE} system should \emph{not} do.  Instead, Yao suggests\cite{yao1986generate} that a correct system should be compared to an ideal-oracle that fulfills three properties, and that a \ac{SFE} system is correct if it performs identically to this imagined ideal-oracle.

This imagined ideal-oracle takes \ac{f}, \ac{P1}'s input (\ponein) and \ac{P2}'s input (\ptwoin), executes the given function with the values provided, and then returns the function's output to both parties ($u \leftarrow f(i_{P1}, i_{P2})$).


\subsubsection{Validity}

A \ac{SFE} system must perform indistinguishably from an ideal-oracle in being able to correctly calculate the given function. Note that this does not guarantee a correct result, since the function being computed in a secure manner could itself have a logic error in it, nor does it guarantee to produce any answer, if one of the parties submits an invalid input to the computation. This \emph{validity} requirement merely requires that the function produce the same result as the insecure (or ``pre-secured'') version of the function being evaluated, given the same inputs.


\subsubsection{Privacy}

A \ac{SFE} system must also perform indistinguishably from an ideal-oracle in preventing preventing \ac{P2} from learning about \ponein\, provided \ac{P1} follows the protocol.  The same must also hold for preventing \ac{P1} from learning about \ptwoin.

Note that that this definition of \emph{privacy} does not guarantee that \ac{P1} is not able to learn \ac{P2}'s input by examining the function's result (if the function being executed allows for such reverse engineering).  If, for example, the function being evaluated securely is multiplication, the fact that \ac{P1} can learn \ptwoin\ through $u/i_{P1}$ does not violate this \emph{privacy} property; \ac{P1} could learn \ptwoin\ in this scenario given an ideal-oracle as well.  This does not mean that \ac{SFE} cannot be used to protect the \emph{privacy} of each parties inputs, only that some functions (such as integer multiplication) do not make sense for two-party \ac{SFE}.

\subsubsection{Fairness}

Finally, a \ac{SFE} system must perform indistinguishably from an ideal-oracle in preventing one party from learning the output of \emph{f} while learning it themselves.  In order words, \ac{P1} should not be able to learn the output of \emph{f} while denying it to \ac{P2}, and vise-versa.

\subsection{Adversary Models}

In addition to defining the properties a \ac{SFE} should have, its necessary to define under which conditions those properties must hold.  While the relevant literature contains many different terms for an adversary's willingness to deviate from the protocol, and many gradations between 100\% honest and 100\% malicious, this paper generalizes the types of attackers into two categories, at the extremes of the attacker spectrum.

A \ac{SFE} protocol is said to be secure against under a given adversary model if the given \ac{SFE} protocol can provide the three above mentioned security properties against any party following the assumptions of the adversary model.

\subsubsection{Semi-Honest}

A \emph{semi-honest} adversary is assumed to follow all required steps in a protocol, but will also look for all advantageous information leaked from the execution of the protocol, such as intermediate values, control flow decisions, or values derivable from the same\cite{goldreich1998secure}.  Additionally, \emph{semi-honest} adversaries are assumed to be selfish, in that they will take any steps that will benefit themselves if the benefit is greater than the harm, within the constraints imposed by the protocol.


\subsubsection{Malicious}

A \emph{malicious} adversary is assumed to arbitrarily deviate from the protocol at any point, and in whenever way it might benefit them\cite{goldreich1998secure}.  This includes proving deceptive or incorrect values, aborting a protocol at anytime, or otherwise taking any steps that could reach a desirable outcome.  This is the most difficult type of adversary to secure against; a system that is secure against \emph{malicious} adversaries is also therefor secure against \emph{semi-honest} adversaries.
