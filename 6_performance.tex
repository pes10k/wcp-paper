\section{Protocol Performance}
\label{sec:performance}

Yao's protocol gives a polynomial time solution for the \ac{SFE} problem, both in the \emph{semi-honest} and \emph{malicious} cases (once the adjustments made in section \ref{sec:security} are made).  However, while Yao's protocol is by this definition ``efficient'', it is also costly, and for many problems prohibitively so.  For example, Kreuter, shelat and Shen\cite{kreuter2012billion} found that computing the edit distance of two 4095-bit strings required a circuit of over 5.9 billion gates, even given with a highly optimized circuit.

A great deal of work has been done to make the protocol less expensive to execute.  This work broadly falls into three categories: 1) communication cost optimization that reduce the communication cost of the protocol by minimizing the amount of information that must be shared between the two parties, 2) execution optimizations that that allow for the same number of gates to be executed in a shorter amount of time, and 3) circuit optimizations that reducing the number of gates needed to compute the function.

Optimizations do not always cleanly fall into only one of these categories, and improvements in one area often have spill over benefits in another.  For example, reducing the number of gates needed to compute a circuit also reduces the number of gates that need to be communicated between parties.  The following categorization is more meant to provide an intuition about the main role of each optimization, and less a strict taxonomy of contributions.


\subsection{Communication Optimizations}

The communication costs of transmitting a garbled circuit from \ac{P1} to \ac{P2} dwarfs all other communication related costs in Yao's protocol\footnote{For all but the most trivial functions.}.  To see why, recall that circuits can grow to contain billions of gates, and that each wire connecting each of these gates is represented by four multi-byte strings, meaning each garbled circuit can be gigabytes in size. This problem is made worse when considering the protocol in the \emph{malicious} setting, where the \emph{cut-and-check} strategy requires \ac{P1} to send many copies of the garbled circuit to \ac{P2}. Minimizing the amount of information that must be communicated between the parties in the protocol is therefor a significant issue in making Yao's protocol practical.

\subsubsection{Random Seed Checking}
\label{sec:randomseed}

A solution to this problem was presented by Goyal, Mohassel and Smith\cite{goyal2008efficient}. Their technique significantly reduces the communication costs of Yao's protocol in two steps.

First, instead of having \ac{P1} assign values for each wire in the circuit randomly, \ac{P1} selects a random seed for each garbled version of the circuit, then uses that random seed to deterministically generate each of the the random values used in the circuit.

Second, instead of sending \ac{P2} $m$ copies of the garbled circuit during the \emph{cut-and-check} phase, \ac{P1} instead sends \ac{P2} ``commitments'' for each version of the circuit.  \ac{P2} then chooses $m/2$ circuits for \ac{P1} to reveal.  \ac{P1} then sends \ac{P2} the random seed used for each selected circuit, along with any structural information \ac{P2} needs to generate the garbled circuit from the random seed.

Once \ac{P2} has verified that the revealed circuits are correct, she then checks that \ac{P1}'s commitments for each circuit are correct (loosely, by hashing each random-seed generated circuit and seeing if it matches the corresponding commitment).  Finally, \ac{P1} sends \ac{P2} the remaining $m/2$ circuits for \ac{P2}'s evaluation.

This technique reduces the communication overhead of the protocol by approximately $1/2$, since the commitments \ac{P1} sends are constant in size and much much smaller than the size of a circuit.


\subsection{Execution Optimizations}

This subsection describes several techniques that have been discovered to allow parties to more quickly compute secure versions Yao's protocol without needing to significantly change how the circuit is stored or how information is shared between the two parties.  These other techniques are discussed in later subsections.

\subsubsection{Fast Table Lookups}

The \emph{fast table lookups}\footnote{This name for the technique comes from\cite{huang2011faster}, though versions of it are in work at least as early as\cite{malkhi2004fairplay}.} technique speeds up \ac{P2}'s evaluation of a circuit by removing the need for \ac{P2} to attempt to decrypt each row of each gate's garbled truth table until she finds a value that decrypts correctly.  Instead, the circuit constructor adds an additional bit to the end of each garbled output value. This additional bit serves as half of an index into the next gate's garbled truth table. Since each each garbled truth table contains four output values, and each gate has two input wires (each with one index bit), combining the index bits from both input values can uniquely identify which of the four values in the gate's garbled truth table the input values decrypt.

Note that since the order of the rows each garbled truth table is randomized during construction, these index values do not reveal any information about the underlying values, and thus do not affect the security of the the system.

Further note that the approach described above functionally equivalent to the method described in\cite{malkhi2004fairplay}, but just described from opposite direction.  Milkhi decide the order of the entries in the garbled truth table based on the assigned index bits on each input value.  The above description achieves the same outcome in reverse by randomly ordering the garbled truth table and then assigning the correct index bits to the values of the input strings\footnote{I selected the latter approach because it seemed easier to explain, given the need to describe the standard protocol first in section \ref{sec:protocol}.}.

\subsubsection{Pipelined Circuit Execution}
\label{sec:piplinedexecution}

Garbled representations of circuits computing even simple functions can grow extremely large, making them difficult to store in memory for both the generating and computing party, as well as time consuming to generate (since \ac{P2} is waiting idle while \ac{P1} is garbling the circuit).  Huang, Evans, et al.\cite{huang2011faster} realized that the garbling and executing processes could be partially conducted in parallel, with \ac{P1} sending \ac{P2} the garbled gates as quickly as he is able to prepare them, and \ac{P2} continuing to compute as long as she has at least gate to compute for which she has inputs for.

This technique has two benefits.  It prevents either party from needing to keep an entire circuit in memory (though the optimal strategy for minimizing the working set needed in memory is an open problem\cite{kreuter2012billion}), and it roughly reduces the time needed to compute a garbled circuit from $t_{garble} + t_{OT} + t_{evaluate}$ to $max(t_{garble}, t_{evaluate}) + t_{OT}$.

The above construction works in the \emph{semi-honest} case, but seems unworkable in the \emph{malicious} case.  Recall that an important part of securing the protocol in the \emph{malicious} case comes from the \emph{cut-and-choose} protocol, where \ac{P1} generates many copies of the circuit.  \ac{P2} then selects $m/2$ copies to be un-garbled.  This would seem to require that \ac{P2} hold all $m$ circuits simultaneously.  The previously discussed \emph{random seed checking} approach similarly seems to make this pipelining and parallel execution strategy impossible, since it seems to require \ac{P1} to hold all $m$ copies of the circuit until \ac{P2} has made her selection of circuits to verify.

A method for achieving the memory and execution time improvements of this \emph{pipelined circuit execution} technique in the \emph{malicious} case was developed by Kreuter, shelat and Shen\cite{kreuter2012billion}. Their solution is to have \ac{P1} generate each circuit twice, once before \ac{P2} selects which circuits to verify, and then again after \ac{P2} has made her choices.

In the first phase, \ac{P1} generates each circuit, generates a commitment for it, saves the generating random seed, and the discards the circuit before generating the next circuit and commitment.

In the second phase, once \ac{P2} has selected which $m/2$ circuits to evaluate, \ac{P1} can regenerate each garbled circuit, one-at-a-time, and send them to \ac{P2}.  \ac{P2} can, in turn, compute each circuit as she is receiving it, as she would in the \emph{semi-honest} case.  This achieves the intended optimization of neither party needing to store more than one circuit, or hold an entire circuit in memory, without giving up the communication improvements of the \emph{random seed checking} technique.


\subsection{Circuit Optimizations}

A straight forward way of reducing the cost of Yao's protocol is to reduce the size of the garbled gates that must be evaluated. This section discusses several strategies that have been used to reduce the number of gates needed to compute the same function.

\subsubsection{Circuit Simplification}

Reducing the number of gates in the pre-garbled circuit trivially reduces the number of garbled gates that need to be evaluated later on.  This can be though of as a preprocessing stage that optimizes the circuit before garbling it.  Put another way, this state attempts to remove inefficiencies introduce when the underlying circuit was being encoded as a circuit.

Circuit optimization strategies include looking for unused gates, or gates that have no effect on the circuit, finding sub-circuits that can be more efficiently represented by a smaller number of gates, and removing identity gates and sub-circuits, or sets of gates who are guaranteed to evaluate to 0 or 1\cite{kreuter2012billion, pinkas2009secure}.  The benefit of from this type of optimization will be inversely related to the quality of circuits generated by the function-to-circuit translating process.  One study\cite{pinkas2009secure} found a 60\% reduction in circuit size when optimizing circuits generated from a common circuit generator\cite{malkhi2004fairplay}.


\subsubsection{Free XOR Optimization}
\label{sec:freexoropt}

A second strategy for reducing the number of gates needed in a garbled circuit comes form the free XOR strategy, discovered by Kolesnikov and Schneider\cite{kolesnikov2008improved}.  This optimization allows for the circuit constructor to replace all garbled XOR gates in the circuit with a simple XOR operations. This results in the significant improvement of removing four garbled values from the circuit for every XOR gate.

The free XOR technique works by changing how some of the garbled values for wires in the circuit are selected. Recall that by default each garbled value of 0 and 1 for each wire in the circuit is selected randomly.  The free XOR technique instead relates the values of the input wires to XOR gates so that the gate's correct output values can be computed with a single XOR operation, instead of needing to look up the output value in a garble truth table. Since garbled truth tables are no longer needed for all XOR gates, the size of the garbled circuit is reduced by $|XOR gates| \bullet |k|$, where $k$ is the size of the garbled values used in the circuit. The free XOR technique is described more formally in algorithm \ref{alg:freexor}.

\begin{algorithm}[H]
    \floatname{technique}{Algorithm}
    \caption{Free XOR Technique}
    \label{alg:freexor}
    \begin{algorithmic}[1]
        \STATE \ac{P1}, the circuit constructor, generates secret $R \in \{0, 1\}^{k}$, where $k$ is the length of each garbled value in the circuit.
        \STATE Let $X$ be the set of all XOR gates in the circuit, and let $g_{in_0}$ and $g_{in_1}$ refer to the gates in the circuit who's output wires serve as the input wire to gate $g$. Finally, let $k^b_{in_i}$ refer to the $b \in \{0, 1\}$ value of wire leaving $g_{in_i}$ and entering $g$.
        \FOR {$g \in X$}
            \STATE Set $k^1_{in_0} =  R \oplus k^0_{in_0}$ and $k^1_{in_1} =  R \oplus k^0_{in_1}$.
            \STATE Replace $g$ with a function returning $k_{in_0} \oplus k_{in_1}$.
        \ENDFOR
    \end{algorithmic}
\end{algorithm}


\subsubsection{Garbled Row Reduction}
\label{sec:grr}

Pinkas et al.\cite{pinkas2009secure} developed a technique to further reduce the number of garbled values that need to be stored in the garbled circuit.  Their technique, called \emph{garbled row reduction}, removes the need to store one garbled value for each AND and OR gate in the circuit, and does so by building on the \emph{fast table lookups} technique.

\emph{Garbled row reduction} works by special casing one of the four possible indexes into a gate's the garbled truth.  Pinkas et al. select $(0, 0)$ for this special case, but that decision is arbitrary.  For this special case, the the output value for the wire is defined to be a function of the input wire values, instead of a new, randomly garbled value. The circuit evaluator can then receive the output wire's value in this special case by performing some computation equivalent to $k^b_{out} \gets H(k_{in_0}, k_{in_1}, g)$ (where $g$ is a unique identifier for the gate) and assigning an index bit of 0. The value of $b$ would depend on whether the type of gate (AND or OR) and the boolean values represented behind the input wire values that carried the $(0, 0)$ index.

The circuit constructor would the be responsible for correctly populating the rest of the garbled boolean circuit, using the above value for any other rows where the output wire should carry value $b$, and using $k^b_{out} \oplus R$ in the other case (to maintain compatibility with the \emph{free XOR} approach from the previous section).


